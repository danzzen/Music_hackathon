{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "music-recommendation.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Qyad5N69mHqp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gNQza1XvmNmj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!wget -q http://apache.osuosl.org/spark/spark-2.2.1/spark-2.2.1-bin-hadoop2.7.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jA0GI60purJP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!tar xf spark-2.2.1-bin-hadoop2.7.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "14wQVOYLus0s",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vPbynWwyuvM-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.2.1-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mgHmOYJsuxKh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "de0LD1wQu0Zg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "526b0e44-d995-41af-b03f-c2895437f953",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530353662596,
          "user_tz": -330,
          "elapsed": 164243,
          "user": {
            "displayName": "MOHIT YADAV",
            "photoUrl": "//lh3.googleusercontent.com/-gQF4fZEKQsI/AAAAAAAAAAI/AAAAAAAAA9g/veD3u1CINu4/s50-c-k-no/photo.jpg",
            "userId": "110139574823898601884"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from pyspark.mllib.recommendation import *\n",
        "import random\n",
        "from operator import *\n",
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "# conf =SparkConf().setAppName(\"cust data\").setMaster(\"local[*]\")\n",
        "# sc=SparkContext(conf=conf)\n",
        "\n",
        "# ## Loading data\n",
        "\n",
        "\n",
        "\n",
        "artistData=sc.textFile(\"artist_data_small.txt\")\n",
        "artistAlias=sc.textFile(\"artist_alias_small.txt\")\n",
        "userArtistData=sc.textFile(\"user_artist_data_small.txt\")\n",
        "userArtistData.count()\n",
        "userArtistData1=userArtistData.map(lambda line:line.split(\" \")).map(lambda r: (int(r[0]), int(r[1]),int(r[2])))\n",
        "artistAlias1=artistAlias.map(lambda line:line.split(\"\\t\")).map(lambda r: (int(r[0]), int(r[1])))\n",
        "artistData1=artistData.map(lambda line:line.split(\"\\t\")).map(lambda r: (int(r[0]), r[1]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ## Data Exploration\n",
        "\n",
        "\n",
        "mean=userArtistData1.map(lambda r: (int(r[0]), int(r[1]))).groupByKey().map(lambda l:(l[0],len(list(l[1]))))\n",
        "aggr=userArtistData1.map(lambda r: (int(r[0]), int(r[2]))).reduceByKey(lambda a,b:a+b)\n",
        "\n",
        "\n",
        "topThree=aggr.takeOrdered(3, key=lambda x: -x[1])\n",
        "topThree1=sc.parallelize(topThree)\n",
        "a=topThree1.join(mean).map(lambda x: (x[0],x[1][0],x[1][0]/x[1][1]))\n",
        "my_list=a.collect()\n",
        "for list_elems in my_list:\n",
        "    print(\"User \"+str(list_elems[0])+\" has a total play count of \"+str(list_elems[1])+\" and a mean play count of \"+str(list_elems[2]))\n",
        "  \n",
        "\n",
        "\n",
        "# Splitting Data for Testing\n",
        "\n",
        "\n",
        "trainData,validationData,testData=userArtistData1.randomSplit([0.4,0.4,0.2],13)\n",
        "trainData.cache()\n",
        "validationData.cache()\n",
        "testData.cache()\n",
        "\n",
        "\n",
        "# ## The Recommender Model\n",
        " \n",
        "# ### Model Evaluation\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def modelEval(bestModel,Data1, trainData):\n",
        "    a=trainData.map(lambda x: ((x[0]),(x[1]))).groupByKey().map(lambda r: (int(r[0]), list(r[1]))).collect()\n",
        "    object_dict = dict((x[0], x[1]) for x in a)\n",
        "    t=Data1.map(lambda x: ((x[0]),(x[1]))).groupByKey().map(lambda r: (int(r[0]), list(r[1]))).collect()\n",
        "    object_dict1 = dict((x[0], x[1]) for x in t)\n",
        "    allArtists=userArtistData1.map(lambda x: x[1]).distinct()\n",
        "    t1=Data1.map(lambda g:(g[0], g[1]))\n",
        "    unique_test=Data1.map(lambda x: x[0]).distinct().collect()\n",
        "    sum=0\n",
        "    for users in unique_test:\n",
        "        userEval=[]\n",
        "        nonTrainArtists=set(allArtists.collect())-set(object_dict[users])\n",
        "        for art in nonTrainArtists:\n",
        "            userEval.append((users,art))                                      \n",
        "        userEval=sc.parallelize(userEval)    \n",
        "        trueArtist=object_dict1[users]\n",
        "        mod=bestModel.predictAll(userEval)\n",
        "        predictResult=mod.map(lambda l: (l[1],l[2])).takeOrdered(len(trueArtist), key=lambda x: -x[1]) \n",
        "        predictResult1=sc.parallelize(predictResult)\n",
        "        predictResult1=predictResult1.map(lambda f:f[0]).collect()\n",
        "        h=set(predictResult1) & set(trueArtist)\n",
        "        d=len(h)/float(len(predictResult1))\n",
        "        sum=sum+d\n",
        "    return float(sum/float(len(unique_test)))       \n",
        "\n",
        "\n",
        "# ### Model Construction\n",
        "\n",
        "\n",
        "\n",
        "vals = [2, 10, 20]\n",
        "for val in vals:\n",
        "    expModel = ALS.trainImplicit(trainData, rank=val, seed=345)\n",
        "    score=modelEval(expModel, validationData, trainData)\n",
        "    print \"The model score for rank \"+str(val)+\" is\",'%.5f' % score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "bestModel = ALS.trainImplicit(trainData, rank=10, seed=345)\n",
        "modelEval(bestModel, testData, trainData)\n",
        "\n",
        "\n",
        "# ## Trying Some Artist Recommendations\n",
        "# Using the best model above, predicting the top 5 artists for user `2023977` using the [recommendProducts](http://spark.apache.org/docs/1.5.2/api/python/pyspark.mllib.html#pyspark.mllib.recommendation.MatrixFactorizationModel.recommendProducts) function.\n",
        "\n",
        "x=bestModel.recommendProducts(2023977,5)\n",
        "recomendations=sc.parallelize(x)\n",
        "recomendationArtists=recomendations.map(lambda r:r[1]).collect()\n",
        "y=artistAlias1.map(lambda x: ((x[0]),(x[1]))).groupByKey().map(lambda r: (int(r[0]), list(r[1]))).collect()\n",
        "y_dict = dict((x[0], x[1]) for x in y)\n",
        "realArt=artistData1.map(lambda x: ((x[0]),(x[1]))).groupByKey().map(lambda r: (int(r[0]), list(r[1]))).collect()\n",
        "realArt_dict = dict((x[0], x[1]) for x in realArt)\n",
        "i=0\n",
        "for art in recomendationArtists:\n",
        "    if art in realArt_dict.keys():\n",
        "        i=i+1\n",
        "        print \"Artist %d :\"%i+ realArt_dict[art][0]\n",
        "    else:\n",
        "        alias=y_dict[art]\n",
        "        i=i+1\n",
        "        print \"Artist %d :\"%i+ realArt_dict[alias][0]\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User 2064012 has a total play count of 548427 and a mean play count of 9455\n",
            "User 1059637 has a total play count of 674412 and a mean play count of 1878\n",
            "User 2069337 has a total play count of 393515 and a mean play count of 1519\n",
            "The model score for rank 2 is 0.08960\n",
            "The model score for rank 10 is 0.09568\n",
            "The model score for rank 20 is 0.08825\n",
            "Artist 1 :Brand New\n",
            "Artist 2 :Bryan Adams\n",
            "Artist 3 :Franz Ferdinand\n",
            "Artist 4 :Dizzee Rascal\n",
            "Artist 5 :Pixies\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3qu997a7u6Ay",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}